{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TMLSS-VAE-external.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Acmy1z3P3V98",
        "9UiHw8Ie4sl0",
        "a7XoTvOhzFp9",
        "1YwZqHFXyie5",
        "UYeq8SF-4Lmp",
        "wCMHZKfkhyWN",
        "iePLy5C7z_5B",
        "-WyyBOYv0BXV",
        "FGKjcY8o0GeF",
        "njDk4CGSkalW",
        "3CthSKUMjJBP",
        "73AZS7Rfbxj1",
        "jrW5Nrh7b3w1",
        "WO8-O_MVp9h3",
        "0xHqdJ2Eb8UO",
        "K1SkUv8CbYCb",
        "01U3ppUSba9n",
        "NJluooqlbdYG",
        "FMwyujkrKaCp",
        "4-fiNrWg6qRL",
        "UyDb1c-_cDDN",
        "5OmDkc3Vyrd2",
        "aW36aYIO7IEz",
        "Cr1gCMEmVZIB",
        "7vCzjVdPjris",
        "E7KYRykh5oCY",
        "AikrCSKNkDkV",
        "cDV-VHNrk7gS"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "YpCl_L2mfS_x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# VAE training tutorial\n",
        "\n",
        "This is a tutorial training a [VAE](https://arxiv.org/abs/1312.6114) on MNIST and latent analysis\n",
        "\n",
        "Structure:\n",
        "\n",
        "  * create encoder and decoder, choose latent and model distributions.\n",
        "  * VAE training\n",
        "  * check likelihood for overfitting.\n",
        "  * latent analysis\n",
        "  \n",
        "  \n",
        "  Your tasks:\n",
        "  \n",
        "   * define the decoder distribution\n",
        "   * define the encoder distribution\n",
        "   * define the terms of the loss\n",
        "   * define the samples and reconstruction tensors\n",
        "   * run the KL analysis \n",
        "   * run the latent traversal task\n",
        "   * run the colab with a different number of latent dimensions (and see how that affects the kl analysis)\n",
        "   \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "f_lRdLwjSBZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q dm-sonnet\n",
        "!pip install -q seaborn -U"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yp07qGy_fhrp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "We will use Sonnet to define the encoder and decoder networks."
      ]
    },
    {
      "metadata": {
        "id": "k3O60Q5ve1SD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import sonnet as snt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library.\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SuQEapz3fAew",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QnodJ56FY8PW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.set(rc={\"lines.linewidth\": 2.8}, font_scale=2)\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0uWUPtampze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQOPrU_tfljy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "iFjsBLsDCCAC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64  # @param\n",
        "NUM_LATENTS = 20  # @param\n",
        "TRAINING_STEPS = 10000 # @param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5cfQlEC07pal",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "We will use the MNIST dataset. Luckly, TensorFlow comes with a simple way to load it. "
      ]
    },
    {
      "metadata": {
        "id": "5EHWPAsd7u50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6822bd6e-5068-46bd-c0ff-b60be9af7bb5"
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FWipXtlq8Ya9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "06d8406b-8937-45cf-937c-c8d4d2b89764"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.train.images.shape)\n",
        "print(type(mnist.train.images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n",
            "<type 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWded8OecPFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transform the data from numpy arrays to graph tensors.\n",
        "\n",
        "This allows us to use TensorFlow datasets, which ensure that a new batch from the data is being fed at each session.run. This means that we do not need to use feed_dicts to feed data to each session."
      ]
    },
    {
      "metadata": {
        "id": "QmrdDH2ibvGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_tf_data_batch(np_data, shuffle=True):  \n",
        "  # Reshape the data to image size.\n",
        "  images = np_data.reshape((-1, 28, 28, 1))\n",
        "  \n",
        "  # Create the TF dataset.   \n",
        "  dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "  \n",
        "  # Shuffle and repeat the dataset for training.\n",
        "  # This is required because we want to do multiple passes through the entire\n",
        "  # dataset when training.\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(100000).repeat()\n",
        "    \n",
        "  # Batch the data and return the data batch.\n",
        "  one_shot_iterator = dataset.batch(BATCH_SIZE).make_one_shot_iterator()\n",
        "  data_batch = one_shot_iterator.get_next()\n",
        "  return data_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKwY_jfDHZdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4dd4651-7421-408e-d745-3af8e47e83f7"
      },
      "cell_type": "code",
      "source": [
        "real_data = make_tf_data_batch(mnist.train.images)\n",
        "print(real_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Acmy1z3P3V98",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the encoder and decoder (generator) networks"
      ]
    },
    {
      "metadata": {
        "id": "9UiHw8Ie4sl0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Encoder network\n",
        "\n",
        "We use a conv net encoder, and add a linear layer at the end - the latents will be 1D."
      ]
    },
    {
      "metadata": {
        "id": "a7XoTvOhzFp9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise: Fill in the distribution for the encoder\n",
        "\n",
        "Remember: the encoder represents q(z|x)"
      ]
    },
    {
      "metadata": {
        "id": "QBauDYfA4IvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MnistEncoder(snt.AbstractModule):\n",
        "  \"\"\"The learned encoder distribution q(z|x).\n",
        "  \n",
        "    The output distribution will be a Normal distribution for each latent,\n",
        "    with the mean and variance of the distribution being learned by gradient \n",
        "    descent.\n",
        "    \n",
        "    The variables of this module get a loss from both the likelihood and \n",
        "    the KL term. We do not have to worry about the reparamtrization trick, since\n",
        "    TensorFlow implements that for us, for the Normal distribution.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, name='MnistEncoder'):\n",
        "    super(MnistEncoder, self).__init__(name=name)\n",
        "\n",
        "  def _build(self, input_image):\n",
        "    \"\"\"Constructs the encoder graph.\n",
        "\n",
        "    Args:\n",
        "      input_image: `tf.Tensor` input to be used by the encoder.\n",
        "\n",
        "    Returns:\n",
        "      `tf.Tensor` output with the decision of the encoder.\n",
        "    \"\"\"\n",
        "    \n",
        "    conv2d = snt.nets.ConvNet2D(\n",
        "        output_channels=[8, 16, 32, 64, 128],\n",
        "        kernel_shapes=[[5, 5]],\n",
        "        strides=[2, 1, 2, 1, 2],\n",
        "        paddings=[snt.SAME],\n",
        "        activate_final=True,\n",
        "        activation=tf.nn.relu,\n",
        "        use_batch_norm=False)\n",
        "\n",
        "    convolved = conv2d(input_image)\n",
        "    \n",
        "    # Flatten the data to 2D for getting the mean and variance from the encoder.\n",
        "    flat_data = snt.BatchFlatten()(convolved)\n",
        "    \n",
        "    # TODO: build the encoder distribution q(z|x) for the given input.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YwZqHFXyie5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise: Fill in the distribution for the decoder\n",
        "\n",
        "Remember: the decoder represents p(x|z)"
      ]
    },
    {
      "metadata": {
        "id": "UYeq8SF-4Lmp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Decoder network\n",
        "\n",
        "We use a simple Transpose convolutional network. Because the input to the model is 2 dimensional, we first use a linear layer to transform the input latents to a size suitable for the conv network."
      ]
    },
    {
      "metadata": {
        "id": "L_hok1Yo3VXm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MnistDecoder(snt.AbstractModule):\n",
        "  \"\"\"The learned decoder distribution p(x|z).\n",
        "  \n",
        "    The variables of this module get a loss from the likelihood term and are\n",
        "    trained using gradient descent.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, name='MnistDecoder'):\n",
        "    super(MnistDecoder, self).__init__(name=name)\n",
        "\n",
        "  def _build(self, inputs):\n",
        "    \"\"\"Constructs the generator graph.\n",
        "\n",
        "    Args:\n",
        "      inputs: `tf.Tensor` with the input of the generator.\n",
        "\n",
        "    Returns:\n",
        "      `tf.Tensor`, the generated samples.\n",
        "    \"\"\"\n",
        "    linear = snt.Linear(7 * 7 * 64)\n",
        "    inputs = linear(inputs)\n",
        "    \n",
        "    # Reshape the data to have rank 4.\n",
        "    inputs = snt.BatchReshape((7, 7, 64))(inputs)\n",
        "    inputs = tf.nn.relu(inputs)\n",
        "\n",
        "    net = snt.nets.ConvNet2DTranspose(\n",
        "        output_channels=[32, 1],\n",
        "        output_shapes=[[14, 14], [28, 28]],\n",
        "        strides=[2],\n",
        "        paddings=[snt.SAME],\n",
        "        kernel_shapes=[[5, 5]],\n",
        "        use_batch_norm=False)\n",
        "\n",
        "\n",
        "   # TODO: build the decoder distribution p(x|z) for the given input latents.\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCMHZKfkhyWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## VAE logic\n",
        "\n",
        "Variational bound:\n",
        "\\begin{equation}\n",
        " \\mathbb{E}_{p^*(x)} \\mathbb{E}_{q(z|x)} \\log p_\\theta(x|z)  - \\mathbb{E}_{p^*(x)} KL(q(z|x)||p(z))\n",
        "\\end{equation}\n",
        "\n",
        "The aim of the model is to maximize the variational lower bound, so the negative of the bound is minimized.\n",
        "\n",
        "<h2 align=\"center\"></h2> <img src=\"http://elarosca.net/vae.png?format=100w\" width=500 >\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JD-iLt9eibPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25e6b6f3-685f-4c2c-8085-819622f539bc"
      },
      "cell_type": "code",
      "source": [
        "encoder = MnistEncoder()\n",
        "decoder = MnistDecoder()\n",
        "\n",
        "# Zero mean, unit variance prior.\n",
        "prior_mean = tf.zeros(shape=(BATCH_SIZE, NUM_LATENTS), dtype=tf.float32)\n",
        "prior_scale = tf.ones(shape=(BATCH_SIZE, NUM_LATENTS), dtype=tf.float32)\n",
        "prior = tf.distributions.Normal(loc=prior_mean, scale=prior_scale)\n",
        "\n",
        "print('Latent samples {}'.format(prior.sample().shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latent samples (?, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s61KNPHvk2VS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the graph for the loss\n",
        "\n",
        "Since we want to maximize the bound on the log probability of the data, we minimize the negative of the bound.\n",
        "\n",
        "The terms of the bound are: the log prob term, and the KL term."
      ]
    },
    {
      "metadata": {
        "id": "iePLy5C7z_5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Log prob term\n",
        "\n",
        "Reminder: this term ensures reconstructions will look good.\n",
        "\n",
        "\\begin{equation}\n",
        " \\mathbb{E}_{p^*(x)} \\mathbb{E}_{q^(z|x)} \\log p_\\theta(x|z)\n",
        "\\end{equation}\n"
      ]
    },
    {
      "metadata": {
        "id": "-WyyBOYv0BXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### KL term\n",
        "\n",
        "Reminder: this term ensures model samples (obtained by sampling from the prior and doing a forward pass through the decoder) are close to data reconstructions (which are obtained by doing a pass through the encoder, getting posterior samples, and then using them to generate data reconstructions).\n",
        "\n",
        "\\begin{equation}\n",
        " - \\mathbb{E}_{p^*(x)} KL(q(z|x)||p(z))\n",
        "\\end{equation}"
      ]
    },
    {
      "metadata": {
        "id": "VwLMBKr0zbhn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise: Fill in the individual losses\n",
        "\n",
        "The KL and the reconstruction loss."
      ]
    },
    {
      "metadata": {
        "id": "pvm-DnXpZdkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bound_terms(data_batch):\n",
        "\n",
        "  # Define the posterior distribution\n",
        "  posterior_distribution = ...\n",
        "  \n",
        "  # Samples from q(z |x )   \n",
        "  latent_sample = ...\n",
        "\n",
        "  # Log prob of the original data under p_theta(  |z)\n",
        "  all_log_probs = ...\n",
        "\n",
        "  # Since we used broadcasting, log_prob of a Bernoulli will return a log_prob for \n",
        "  # each dimension.\n",
        "  all_log_probs.shape.assert_is_compatible_with([BATCH_SIZE, 28, 28, 1])\n",
        "\n",
        "  # Reduce sum over the data dimensions\n",
        "  likelihood_term = tf.reduce_sum(all_log_probs, axis=[1, 2, 3])\n",
        "\n",
        "  # Reduce mean over the batch dimensions\n",
        "  likelihood_term = tf.reduce_mean(likelihood_term)\n",
        "\n",
        "  # Define the KL divergence   \n",
        "  all_kls = ...\n",
        "  all_kls.shape.assert_is_compatible_with([BATCH_SIZE, NUM_LATENTS])\n",
        "\n",
        "  # Reduce sum over the latent dimensions.\n",
        "  kl_term = tf.reduce_sum(all_kls, axis=[1])\n",
        "\n",
        "  # Reduce over the batch dimension.\n",
        "  kl_term = tf.reduce_mean(kl_term)\n",
        "  \n",
        "  return likelihood_term, kl_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGKjcY8o0GeF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise: Total Loss \n",
        "\n",
        "Combine the likelihood term and the KL term to define the likelihood bound and the loss.\n",
        "\n",
        "Remember: we will minimize the loss, but we want to maximize the bound."
      ]
    },
    {
      "metadata": {
        "id": "v3R5gjUC0IMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Maximize the data likelihodd and minimize the KL divergence between the prior and posterior\n",
        "likelihood_term, kl_term = bound_terms(real_data)\n",
        "train_bound = ...\n",
        "loss =  ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njDk4CGSkalW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise: Define the sample and reconstruction tensors\n",
        "\n",
        "Note: VAEs have no direct cost on samples. The quality of the samples improves, because the likelihood term ensures that the model will reconstruct well, while the KL term brings samples close to reconstructions.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RDUbZFB4kb2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samples = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmtGtWstet6h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reconstructions = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CthSKUMjJBP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the optimizer\n",
        "\n",
        "We will train the encoder and decoder jointly, to minimize the same loss."
      ]
    },
    {
      "metadata": {
        "id": "h-oiJ8ybjKn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(0.001, beta1=0.9, beta2=0.9)\n",
        "update_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73AZS7Rfbxj1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the tensorflow session"
      ]
    },
    {
      "metadata": {
        "id": "3Qvja62rEClx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "# Initialize all variables\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrW5Nrh7b3w1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "wgvYiuQib5FY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "82aaa5ea-e614-4f97-9372-deffbaad7da6"
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in xrange(TRAINING_STEPS):\n",
        "  sess.run(update_op)\n",
        "  \n",
        "  if i % 100 == 0:\n",
        "    iteration_loss = sess.run(loss)\n",
        "    print('Iteration {}. Loss {}'.format(i, iteration_loss))\n",
        "    losses.append(iteration_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0. Loss 608.814880371\n",
            "Iteration 100. Loss 213.377548218\n",
            "Iteration 200. Loss 194.081817627\n",
            "Iteration 300. Loss 164.966598511\n",
            "Iteration 400. Loss 144.333953857\n",
            "Iteration 500. Loss 137.072845459\n",
            "Iteration 600. Loss 132.694793701\n",
            "Iteration 700. Loss 122.336486816\n",
            "Iteration 800. Loss 116.622253418\n",
            "Iteration 900. Loss 122.743522644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WO8-O_MVp9h3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize the loss in time"
      ]
    },
    {
      "metadata": {
        "id": "XlA-gGsnqA-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(losses, label='Negative log likelihood Bound')\n",
        "plt.xlabel('Time')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xrd62Qj7WULf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xHqdJ2Eb8UO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize samples, reconstructions"
      ]
    },
    {
      "metadata": {
        "id": "_m7aF5q8Yao6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gallery(array, ncols=10, rescale=True):\n",
        "    if rescale:\n",
        "      array = (array + 1.) / 2\n",
        "    nindex, height, width, intensity = array.shape\n",
        "    nrows = nindex//ncols\n",
        "    assert nindex == nrows*ncols\n",
        "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
        "    result = (array.reshape(nrows, ncols, height, width, intensity)\n",
        "              .swapaxes(1,2)\n",
        "              .reshape(height*nrows, width*ncols, intensity))\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1eU3llAAb-lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3af74443-4ffd-4307-8e3c-30e933fb84eb"
      },
      "cell_type": "code",
      "source": [
        "real_data_examples = sess.run(real_data)\n",
        "final_samples = sess.run(samples)\n",
        "data_reconstructions = sess.run(reconstructions)\n",
        "print(data_reconstructions.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K1SkUv8CbYCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Real data"
      ]
    },
    {
      "metadata": {
        "id": "Fpw4vXGgM2re",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "ea9ec94c-12d9-470c-df2b-5baf74f636ca"
      },
      "cell_type": "code",
      "source": [
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(gallery(real_data_examples, ncols=8).squeeze(axis=2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb996fe9d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAEICAYAAABxpmCnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb9998c4550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "01U3ppUSba9n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Samples"
      ]
    },
    {
      "metadata": {
        "id": "_0mUKS3AMYmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(gallery(final_samples, ncols=8).squeeze(axis=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJluooqlbdYG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reconstructions"
      ]
    },
    {
      "metadata": {
        "id": "7Kzn8Ksoe_p-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(gallery(data_reconstructions, ncols=8).squeeze(axis=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMwyujkrKaCp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Final training log prob aver multiple batches"
      ]
    },
    {
      "metadata": {
        "id": "T9eTjJ8jKml8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_TEST_BATCHES = 10 # @param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNbyFu9IKk_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf695cf2-1c2a-401e-a512-b81e9af0f594"
      },
      "cell_type": "code",
      "source": [
        "train_log_prob = []\n",
        "\n",
        "for _ in xrange(NUM_TEST_BATCHES):\n",
        "  train_log_prob.append(sess.run(train_bound))\n",
        "  \n",
        "train_avg_log_prob = np.mean(train_log_prob)\n",
        "  \n",
        "print('Averaged training log prob bound {}'.format(train_avg_log_prob))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Averaged training log prob -116.380203247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4-fiNrWg6qRL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise: Checking for overfitting - test likelihoods\n",
        "\n",
        "\n",
        "We want to ensure that the model has not overfitted - to do that, we see if it gives a higher likelihood to training data compared to test data. If this is the case, we can conclude the model is overfitting."
      ]
    },
    {
      "metadata": {
        "id": "UyDb1c-_cDDN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get test data"
      ]
    },
    {
      "metadata": {
        "id": "Hia807m26osw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data_batch = make_tf_data_batch(mnist.test.images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJQwUUg_n9bB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_bound = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb8uoEkboAXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20ab6a0c-06cc-4a09-d6d0-d00470b4cbb9"
      },
      "cell_type": "code",
      "source": [
        "test_log_prob = []\n",
        "\n",
        "for _ in xrange(NUM_TEST_BATCHES):\n",
        "  test_log_prob.append(sess.run(test_bound))\n",
        "  \n",
        "test_avg_log_prob = np.mean(test_log_prob)\n",
        "  \n",
        "print('Averaged test log prob bound {}'.format(test_avg_log_prob))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Averaged test log prob -115.400169373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5OmDkc3Vyrd2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyse the structure of the latent variables\n",
        "\n",
        "VAEs are generative and inference models. So far we have looked at samples, and reconstructions, but we have not looked at the learned representations. \n",
        "\n",
        "We will now analyze the learned VAE representations by looking at the KLs per latent, but also by doing latent space traversals.\n",
        "\n",
        "Remember that the KL term is important, since the KL term ensures that the quality of the samples is going to be close to that of the reconstrunctions.\n"
      ]
    },
    {
      "metadata": {
        "id": "Bzm9uGiz6Mf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_batches = int(mnist.train.images.shape[0] / BATCH_SIZE)\n",
        "data_batch = make_tf_data_batch(mnist.train.images, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjYhRWj_5TSf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "posterior_distribution = encoder(data_batch)\n",
        "\n",
        "all_kls = tf.distributions.kl_divergence(posterior_distribution, prior)\n",
        "all_kls.shape.assert_is_compatible_with([BATCH_SIZE, NUM_LATENTS])\n",
        "\n",
        "# Reduce over the batch dimension.\n",
        "kls = tf.reduce_mean(all_kls, axis=[0])\n",
        "kls.shape.assert_is_compatible_with([NUM_LATENTS])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LhVQmrAP6D0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aggregate_kl = np.zeros([NUM_LATENTS])\n",
        "for _ in xrange(num_batches):\n",
        "  aggregate_kl += sess.run(kls)\n",
        "  \n",
        "aggregate_kl /= num_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aW36aYIO7IEz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot the kl divergences per latent\n",
        "\n",
        "Because we used a factorizable prior (a Gaussian with unit covariance), the KL divergence\n",
        "also factorizes, and we can see a KL divergence per unit). Here we analyze the KL divergence of each unit, to see how the model uses each latent unit.\n",
        "\n",
        "We will see that if we increase the number of latent variables, the VAE \"turns off\" units, by setting their distribution to that of the prior."
      ]
    },
    {
      "metadata": {
        "id": "eEQlhyYc7G_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_grid_size(num_latents):\n",
        "  num_latents_sqrt = np.sqrt(num_latents)\n",
        "  width = int(num_latents_sqrt)\n",
        "  while num_latents % width !=0:\n",
        "    width -= 1\n",
        "  return width, int(num_latents / width)\n",
        "\n",
        "aggregate_kl = np.reshape(aggregate_kl, get_grid_size(NUM_LATENTS))\n",
        "cmap = sns.cubehelix_palette(4, start=2, rot=0, dark=0, light=.96)\n",
        "np.random.shuffle(aggregate_kl)\n",
        "sns.heatmap(aggregate_kl, vmin=0, vmax=2, linewidths=.05, cmap=cmap)\n",
        "plt.axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cr1gCMEmVZIB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Latent space interpolation\n",
        "\n",
        "By doing an interpolation in latent space, we can analyze the behaviour of the model."
      ]
    },
    {
      "metadata": {
        "id": "MYBVXhEM4nES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = np.linspace(0.0, 1.0, 100)\n",
        "a = np.expand_dims(a, axis=1)\n",
        "\n",
        "first_latents = tf.random_normal((1, NUM_LATENTS))\n",
        "second_latents = tf.random_normal((1, NUM_LATENTS))\n",
        "\n",
        "interpolations =  np.sqrt(a) * first_latents + np.sqrt(1 - a) * second_latents\n",
        "# interpolations =  a * first_latents + (1 - a) * second_latents\n",
        "\n",
        "samples_from_interpolations = decoder(interpolations).mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lq9L6Ex74wk3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samples_from_interpolations_np = sess.run(samples_from_interpolations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gj0VCK_z4y7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c74b560f-ece5-4a9b-cd42-69beb10acd45"
      },
      "cell_type": "code",
      "source": [
        "print(samples_from_interpolations_np.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AM9pfkjo41lw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(gallery(samples_from_interpolations_np).squeeze(axis=2))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vCzjVdPjris",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise: change the number of latents (to 100) and see what happens with the KL plot.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E7KYRykh5oCY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Close session"
      ]
    },
    {
      "metadata": {
        "id": "EUEhfo6X5p_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AikrCSKNkDkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reflections\n",
        "\n",
        "* What can VAEs be used for?\n",
        "* How do VAEs learn to sample?"
      ]
    },
    {
      "metadata": {
        "id": "cDV-VHNrk7gS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### VAE samples on other datasets\n",
        "\n",
        "Note: these are samples with the vanilla algorithm, but they can be improved using better complex distributions.\n",
        "\n",
        "#### CIFAR-10\n",
        "<h2 align=\"center\"></h2> <img src=\"http://elarosca.net/cifar_vae_samples_last.jpeg?format=100w\" width=500 >\n",
        "\n",
        "#### CelebA\n",
        "# <h2 align=\"center\"></h2> <img src=\"http://elarosca.net/celeba_vae_samples_last.jpeg?format=100w\" width=500 >\n",
        "\n"
      ]
    }
  ]
}