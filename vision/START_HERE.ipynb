{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "START_HERE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9J7p406abzgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TMLSS2018: ConvNets and Computer Vision Tutorial\n",
        "\n",
        "## Focus of the tutorial: Study on the efficiency and robustness of convolutional neural networks for image classification\n",
        "\n",
        "### Part I (baseline_start.ipynb): Training a baseline convnet classifier\n",
        "- build a simple classifier given a specific architecture structure\n",
        "- get dataset, apply data augmentation (cropping, flipping)\n",
        "- train classifier\n",
        "- check number of parameters\n",
        "\n",
        "### Part II (visualisation_start.ipynb): Visualise saliency maps (e.g. [paper](https://arxiv.org/pdf/1312.6034v2.pdf))\n",
        "- import an already trained model\n",
        "- visualise the gradients of class probabilities w.r.t inputs to obtain saliency maps\n",
        "- visualise inputs that maximize class probabilities \n",
        "\n",
        "### Part III (mobilenet_start.ipynb):  Separable convolutions [Mobilenet](https://arxiv.org/pdf/1704.04861.pdf) \n",
        "- modify the baseline model to use separable convolutions\n",
        "- check number of parameters and compare with above\n",
        "- train the classifier; compare accuracy with baseline\n",
        "\n",
        "\n",
        "### Part IV (distillation_start.ipynb): [Distilling the knowledge](https://arxiv.org/pdf/1503.02531.pdf) from a (larger) teacher model\n",
        "- import an already trained baseline model to use as teacher\n",
        "- use the smaller Mobilenet model as student\n",
        "- add KL distillation loss between teacher and student\n",
        "- train Mobilenet student classifier with this joint loss\n",
        "\n",
        "### Part V (optional): Test robusness of models using simple geometric transformations\n",
        "- several recent papers have shown that convnets are not robust to simple geometric transformations, e.g. [paper1](https://arxiv.org/pdf/1805.12177.pdf), [paper2](https://arxiv.org/pdf/1711.09115.pdf)\n",
        "- starting for example from the visualisation colab in part II, write a function that:\n",
        "\n",
        ">- slides crops over Cifar test set images\n",
        ">- feeds the crops into the pre-trained baseline model\n",
        ">- plots predictions per class per crop. Are they stable?\n",
        "\n",
        "\n",
        "### Conclusion\n",
        "- Convolutional models achieve high accuracy in image classification.\n",
        "- Backpropagation is used for training neural networks, but can also be used to visualise what a network has learnt.\n",
        "- Separable convolutions allows reducing considerably the number of parameters in a model, with limited degradation in performance.\n",
        "- Distillation is a simple technique for training smaller models to achieve accuracy similar to larger models. It can be used on its own or in conjunction with separable convolutions. \n",
        "- Although these models are very good, there are still important open research questions about how to make them more robust to various attacks.  "
      ]
    },
    {
      "metadata": {
        "id": "I3ODIojOHmtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}